# Audio/Video Transcription Pro (v5.3-PROFESSIONAL)

Профессиональная программа транскрибации с эвристической диаризацией на базе **OpenAI Whisper** (через **faster-whisper / CTranslate2**) и **PySide6**. Обработка выполняется локально, сетевых запросов нет.

## Возможности
- Графический интерфейс: выбор файла, прогресс, статус, логи.
- Whisper-модели: `tiny`, `base`, `small`, `medium`, `large-v3`.
- Язык: `ru`, `en` или автоопределение.
- VAD и предобработка аудио (FFmpeg + high/low-pass).
- «Живая» выдача сегментов во время распознавания.
- Экспорт результатов: TXT, DOCX (при наличии `python-docx`), JSON.
- Статистика по задаче (время, число сегментов, скорость и т.д.).
- Аккуратная очистка памяти и GPU-кэша для стабильной работы.
- Диаризация: простая эвристика по паузам (без внешних моделей).

## Требования
- Python 3.9–3.11.
- Обязательно: `faster-whisper`, `PySide6`, установленный FFmpeg (в `PATH` или `ffmpeg.exe` рядом с приложением).
- Опционально: `PyTorch` (для CUDA/GPU), `python-docx` (DOCX-экспорт), `psutil` (метрики памяти).

## Установка

Минимум:
```bash
pip install faster-whisper PySide6
```
Опционально:
```bash
pip install python-docx psutil
```

Для GPU установите подходящую сборку PyTorch под вашу версию CUDA (см. официальную документацию PyTorch).

## FFmpeg
- Положите `ffmpeg.exe` рядом с приложением или установите FFmpeg и добавьте в `PATH`.
- Наличие FFmpeg проверяется на старте и при извлечении аудио.

## Запуск
```bash
python transcription_pro.py
```
При первом запуске модели Whisper будут докачаны библиотекой `faster-whisper` в кэш (см. логи и «Информация о системе» в приложении).

## Использование
1. Выберите медиа-файл (`.mp4`, `.mkv`, `.avi`, `.mov`, `.webm`, `.mp3`, `.wav`, `.m4a`, `.aac`, `.flac`, `.ogg`).
2. Настройте язык, модель, при необходимости включите диаризацию и параметры VAD.
3. Нажмите «НАЧАТЬ ТРАНСКРИБАЦИЮ». Прогресс и логи — во вкладке «ЛОГИ», сегменты — в «ЖИВАЯ ТРАНСКРИПЦИЯ».
4. Сохраните результат: TXT / DOCX / JSON.

## Качество и производительность
- Модели: `tiny/base` — быстрее, ниже качество; `medium/large-v3` — лучше качество, больше память/время.
- При наличии CUDA используется `device=cuda` и обычно `compute_type=float16` (при малом VRAM автоматически может примениться `int8`).
- VAD часто ускоряет обработку и улучшает результат на «шумных» записях.
- Диаризация здесь простая (по паузам). Для точной диаризации нужны спец-модели (в проект не входят).

## Типичные проблемы
- «faster_whisper не установлен» — установите пакет `faster-whisper`.
- «FFmpeg не найден» — установите FFmpeg или положите `ffmpeg.exe` рядом; проверьте `PATH`.
- CUDA OOM — используйте меньшую модель или CPU; закройте другие GPU-приложения.
- Пустой результат — проверьте качество записи и громкость.
- 
## Hugging Face токен (опционально)

Если загрузка моделей с Hugging Face у вас ограничена, **вставьте свой HF‑токен (hf_...)**. В код ничего добавлять не требуется — `faster-whisper` и `huggingface_hub` подхватят токен автоматически.

Способ 1 — через CLI (рекомендуется):
```
pip install huggingface_hub
huggingface-cli login
```

Способ 2 — через переменную окружения:

Windows (PowerShell):
```
$env:HUGGING_FACE_HUB_TOKEN="hf_xxx"
```

